{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1L-KayPPrWCCQaPje2dbfvaQ3rrh-7gWx","timestamp":1688505774452},{"file_id":"1PULUaYWgWDaPy70CFNGK3KHCnMfNRqsv","timestamp":1589893741141},{"file_id":"1SXOB9mbYEOPg-lV87MUGMPNlIFbxImi0","timestamp":1587765054328}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"5SxyZu2W3CUE"},"source":["Começamos removendo o arquivo `Iris.csv`, se ele já existe.\n"]},{"cell_type":"code","metadata":{"id":"6I9mhp-y2M1g"},"source":["!rm -rf Iris.csv"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a7WVykQC3Mdp"},"source":["Aqui criamos uma interface para upload do arquivo `Iris.csv` (assumimos que o arquivo vai ser enviado exatamente com esse nome). Você pode baixar esse arquivo [daqui deste link](https://drive.google.com/uc?id=1d3NbjXro_BfnYpFm66ETBfe7ubAZPAoL)."]},{"cell_type":"code","metadata":{"id":"SvTqZKzDnJln","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1606451593343,"user_tz":180,"elapsed":41840,"user":{"displayName":"Rodrigo Guerra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtpPLk6oBlEu_rx65qxwz5xbazuqYDx1kEPz6tTAM=s64","userId":"11304502163793688490"}},"outputId":"0307b598-849b-4ad3-97ce-b6df076953ad"},"source":["from google.colab import files\n","import io\n","\n","# A variável upload é um dicionário com todos\n","# arquivos que foram enviados\n","uploaded = files.upload()\n","\n","# A variável f é o arquivo de nome Iris.csv\n","# buscado no dicionário acima.\n","f = io.BytesIO(uploaded['Iris.csv'])"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-fcd2ccb8-03d3-4ab5-9f5e-19ea5f43ad48\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-fcd2ccb8-03d3-4ab5-9f5e-19ea5f43ad48\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving Iris.csv to Iris.csv\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WLJhW3bl3x6b"},"source":["Nas linhas abaixo zeramos o cursor do arquivo e lemos todas as linhas do arquivo em `lines`."]},{"cell_type":"code","metadata":{"id":"f7-KRHha1kLC"},"source":["# Zeramos o cursor para garantir que a leitura\n","# do arquivo inicie do início\n","f.seek(0)\n","\n","# A variável lines é uma lista que contém as strings\n","# que representam cada linha do arquivo lido.\n","lines = f.readlines()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vLJHSh2i4MUf"},"source":["Abaixo criamos as matrizes dos dados de entrada e saída correspondentes, vazias mas já com as dimensões corretas."]},{"cell_type":"code","metadata":{"id":"l2aAziOo7kA-"},"source":["import numpy as np\n","\n","# Aqui criamos as matrizes de entradas e saídas correspondentes\n","# ainda vazias\n","X = np.zeros((len(lines)-1,4)) # 4 entradas\n","Y = np.zeros((len(lines)-1,3)) # 3 saídas (one-hot encoding)\n","\n","# Teremos 3 categorias. O vetor abaixo lista as strings\n","# que representam as categorias possíveis\n","cat = np.array(['Iris-setosa','Iris-versicolor','Iris-virginica'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yqtS_fdF4mMR"},"source":["No laço abaixo populamos as matrizes `X` e `Y`."]},{"cell_type":"code","metadata":{"id":"zvBA3O9116lg"},"source":["# Para cada linha do arquivo, exceto\n","# a primeira linha que é o cabeçalho\n","for i, line in enumerate(lines[1:]):\n","\n","  # Aqui decodificamos a linha para transformar\n","  # de binário para caracteres ascii, e descartamos\n","  # o último caractere que representa uma nova linha\n","  s = line.decode()[:-1]\n","\n","  # Aqui separamos os dados por vírgulas,\n","  # descartando o primeiro valor que é o id\n","  # pois usaremos i do laço como id.\n","  _,sl,sw,pl,pw,sp = s.split(',')\n","\n","  # Transformamos as strings que representam\n","  # as dimensões de sépala e pétala para ponto\n","  # flutuante.\n","  sl = float(sl)\n","  sw = float(sw)\n","  pl = float(pl)\n","  pw = float(pw)\n","\n","  # Aqui populamos as matrizes X e Y com os dados\n","  # coletados.\n","  X[i:] = np.array([sl,sw,pl,pw])\n","  Y[i:] = (cat == sp).astype('float') # Atenção para essa linha!\n","\n","  # A última linha acima merece uma explicação mais longa:\n","  # Nessa linha fazemos um teste booleano, comparando cada\n","  # elemento do vetor cat com a string daquela linha do arquivo.\n","  # Para os elementos onde a comparação der verdadeiro, teremos\n","  # um booleano True, e para os elementos onde a comparação\n","  # der falso, teremos um booleano False. O resultado da comparação\n","  # do vetor cat com a string sp, na expressão cat == sp resulta\n","  # numa array booleana com mesmo formato que cat, mas com\n","  # valores booleanos True ou False em cada posição. O método\n","  # .astype('float') transforma o resultado em um array de float,\n","  # com 1.0 representando True e 0.0 representando False.\n","  # Então transformamos uma string como 'Iris-setosa' no vetor\n","  # [1.0, 0.0, 0.0] e uma string como 'Iris-versicolor' no vetor\n","  # [0.0, 1.0, 0.0] e assim por diante."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WqlSmWlv6iVH"},"source":["Nas linhas abaixo embaralhamos as amostras para não causar nenhum tipo de tendência no treinamento."]},{"cell_type":"code","metadata":{"id":"Fi-Xaru-YO1a"},"source":["import random\n","\n","# Aqui criamos uma lista de índices\n","# embaralhados\n","indexes = list(range(150))\n","random.shuffle(indexes)\n","\n","# Essa variável T indica quantas amostras\n","# serão usadas para treinamento. As demais\n","# serão usadas para validação\n","T = 140\n","\n","# Aqui preparamos as matrizes dos pares\n","# de dados de treinamento e validação.\n","Xt = np.zeros((T,4))\n","Yt = np.zeros((T,3))\n","Xv = np.zeros((150-T,4))\n","Yv = np.zeros((150-T,3))\n","\n","# Aqui preenchemos as matrizes com os\n","# respectivos valores\n","for i in range(0,T):\n","  Xt[i,:] = X[indexes[i],:]\n","  Yt[i,:] = Y[indexes[i],:]\n","for i in range(0,150-T):\n","  Xv[i,:] = X[indexes[T+i],:]\n","  Yv[i,:] = Y[indexes[T+i],:]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nD-W-rnS-s9W"},"source":["O código abaixo implementa a rede neural com o método de backpropagation."]},{"cell_type":"code","metadata":{"id":"MXes0y1dcXTa"},"source":["# Essa será a função de ativação\n","# utilizada\n","def sigmoid(x):\n","  return 1.0 / (1.0 + np.exp(-x))\n","\n","# Função softmax\n","def softmax(x):\n","  ex = np.exp(x)\n","  s = np.sum(ex)\n","  return ex/s\n","\n","# O código abaixo implementa uma rede\n","# neural ariticial estilo perceptron\n","# com 4 entradas, 8 neurônios escondidos\n","# e 3 saídas\n","class Perceptron:\n","  def __init__(self):\n","\n","    # Pesos e biases da entrada para a camada\n","    # escondida\n","    self.Wh = np.random.random((8,4))*2.0 - 1.0\n","    self.bh = np.random.random((8,1))*2.0 - 1.0\n","\n","    # Pesos e bieases da camada escondida para\n","    # a saída\n","    self.Wo = np.random.random((3,8))*2.0 - 1.0\n","    self.bo = np.random.random((3,1))*2.0 - 1.0\n","\n","    # Esse será o passo de aprendizagem\n","    self.eta = 0.1\n","\n","  def forward(self,x):\n","\n","    # Essa função faz o cálculo da saída\n","    # da rede neural no sentido direto.\n","\n","    # Essa linha garante que x tenha tamanho\n","    # de 4 linhas e 1 coluna\n","    x = np.reshape(x,(4,1))\n","\n","    # Calcula a soma ponderada para a camada escondida\n","    # somado ao bias\n","    self.sh = np.dot(self.Wh,x) + self.bh\n","\n","    # Função de ativação é aplicada à camada escondida\n","    self.zh = sigmoid(self.sh)\n","\n","    # Calcula a soma ponderada para a camada de saída\n","    # somado ao bias\n","    self.so = np.dot(self.Wo,self.zh) + self.bo\n","\n","    # Função de ativação é aplciada à camada de saída\n","    self.zo = softmax(self.so)\n","    return self.zo\n","\n","  def train(self, X, Y):\n","    # Essa função faz um ciclo de\n","    # treinamento em todos os dados\n","    # dos pares X e Y\n","\n","    # A variável Err é o erro acumulado\n","    # que só serve para avaliar a qualidade\n","    # final da rede neural. Na prática não\n","    # precisamos dele para o treinamento\n","    Err = 0.0\n","\n","    # Na linha abaixo obtemos a quantidade\n","    # total de pares\n","    total = X.shape[0]\n","\n","    # Laço de treinamento conforme\n","    # o erro de cada par\n","    for i in range(total):\n","\n","      # Capturamos o vetor de entradas do par\n","      x = X[i,:]\n","      x = np.reshape(x,(4,1))\n","\n","      # Capturamos o vetor de saída do par\n","      y_hat = Y[i,:]\n","      y_hat = np.reshape(y_hat,(3,1))\n","\n","      # Fazemos o cálculo da saída da rede\n","      # neural\n","      y = self.forward(x)\n","\n","      # Calculamos o erro médio, para avaliar\n","      # a evolução da performance. Isso não\n","      # é usado para calcular o ajuste dos\n","      # pesos e biases.\n","      err = - np.sum(y_hat*np.log(y))\n","      Err = Err + err\n","\n","      # Aqui calculamos os deltas de trás para frente\n","      # no sentido inverso (daí o nome backpropagation)\n","\n","      # Primeiro calculamos o delta do erro da saída\n","      # Aqui multiplicamos o erro pela derivada\n","      # da função de ativação na saída. A função\n","      # sigmoide possui uma derivada interessante.\n","      # se z é a sigmoide, a derivada é z*(1-z)\n","      self.do = (y - y_hat)\n","\n","      # O delta da camada escondida é calculado\n","      # usando os pesos para propagar o delta do erro\n","      # da saída para o delta do erro da camada escondida\n","      self.dh = np.dot(self.Wo.T, self.do) \\\n","                 * self.zh * (1.0 - self.zh)\n","\n","      # Agora é só dar um passo, de tamanho eta, na\n","      # direção oposta do gradiente. Lembrando que\n","      # para os pesos, a derivada pessoal é gerada\n","      # computando a multiplicação do delta do erro\n","      # pela saída da camada anterior, gerando uma\n","      # matriz resultante da multiplicação desses\n","      # dois vetores. Para o bias basta usar o próprio\n","      # delta do erro.\n","      self.Wo = self.Wo - self.eta * np.dot(self.do,self.zh.T)\n","      self.bo = self.bo - self.eta * self.do\n","      self.Wh = self.Wh - self.eta * np.dot(self.dh,x.T)\n","      self.bh = self.bh - self.eta * self.dh\n","\n","    # Já fora do laço, dividimos o erro pelo total\n","    # de amostras para normalizar\n","    Err = Err / total\n","\n","    # Retornamos o erro\n","    return Err"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"de8U56yo-_TD"},"source":["Abaixo executamos o código, treinando a rede neural com os dados de treinamento separados anteriormente."]},{"cell_type":"code","metadata":{"id":"pOyjnTNkjbRp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606452810998,"user_tz":180,"elapsed":66877,"user":{"displayName":"Rodrigo Guerra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtpPLk6oBlEu_rx65qxwz5xbazuqYDx1kEPz6tTAM=s64","userId":"11304502163793688490"}},"outputId":"da5b3cec-2b77-44c0-deb0-d3eeeb5ca6a0"},"source":["# Criamos p que é nossa rede neural\n","p = Perceptron()\n","\n","# Treinaremos 10 mil + 1 épocas\n","for i in range(10001):\n","\n","  # Aqui um passo de treinamento\n","  Err = p.train(Xt,Yt)\n","\n","  # A cada mil passos mostramos o erro\n","  # total para verificar se está mesmo\n","  # diminuindo.\n","  if not (i % 1000) or i == 0:\n","    print('Err = ',Err)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Err =  0.9472482260778524\n","Err =  0.07466243808344437\n","Err =  0.030113238248304874\n","Err =  0.02834979507977415\n","Err =  0.0271367514013101\n","Err =  0.02627194575903286\n","Err =  0.02548090925841597\n","Err =  0.023190586927961537\n","Err =  0.01888004416533082\n","Err =  0.01396996479385829\n","Err =  0.007650199816369704\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"egEWbfBa_Nyw"},"source":["Aqui vamos avaliar a performance dessa rede neural treinada, vendo como ela se sai nos dados separados para validação (dados para os quais ela nunca foi treinada)."]},{"cell_type":"code","metadata":{"id":"1CavDK5osyEK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606452810999,"user_tz":180,"elapsed":66873,"user":{"displayName":"Rodrigo Guerra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtpPLk6oBlEu_rx65qxwz5xbazuqYDx1kEPz6tTAM=s64","userId":"11304502163793688490"}},"outputId":"84e07482-c5bd-4dce-8a51-1961e6baad95"},"source":["# Essa linha abaixo serve para suprimir a notação\n","# científica padrão do numpy para facilitar nosso\n","# olho humano comparar os resultados\n","np.set_printoptions(formatter={'float':lambda x: '%+01.2f ' % x})\n","\n","# Para cada amostra de treinamento\n","# nesse laço\n","for i in range(150-T):\n","\n","  # Separamos a entrada\n","  xv = Xv[i,:]\n","\n","  # Calculamos a saída da rede\n","  y = p.forward(xv)\n","\n","  # Separamos a saída esperada\n","  yv = Yv[i,:]\n","\n","  # Mostramos ambos lado a lado\n","  print(y.T[0], yv)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[+0.00  +0.00  +1.00 ] [+0.00  +0.00  +1.00 ]\n","[+0.00  +1.00  +0.00 ] [+0.00  +1.00  +0.00 ]\n","[+0.00  +0.00  +1.00 ] [+0.00  +0.00  +1.00 ]\n","[+0.00  +0.00  +1.00 ] [+0.00  +0.00  +1.00 ]\n","[+0.00  +1.00  +0.00 ] [+0.00  +1.00  +0.00 ]\n","[+0.00  +1.00  +0.00 ] [+0.00  +1.00  +0.00 ]\n","[+1.00  +0.00  +0.00 ] [+1.00  +0.00  +0.00 ]\n","[+0.00  +0.00  +1.00 ] [+0.00  +0.00  +1.00 ]\n","[+0.00  +1.00  +0.00 ] [+0.00  +1.00  +0.00 ]\n","[+1.00  +0.00  +0.00 ] [+1.00  +0.00  +0.00 ]\n"],"name":"stdout"}]}]}