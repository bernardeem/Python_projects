{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPFHGZConyAW5wJ8qHAj5QI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EcxE4Fmi9ThK","executionInfo":{"status":"ok","timestamp":1697552968543,"user_tz":180,"elapsed":5,"user":{"displayName":"Bernardo Ávila","userId":"17720466755867390545"}},"outputId":"157ecc9e-befd-4276-d64c-09ef7b4f6cd7"},"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2]\n"]}],"source":["import numpy as np\n","p = ([[0.4, 0.6],    # probabilidade of R    (RR, RN)\n","      [0.2, 0.8]])   # probabilidade of N    (NR, NN)\n","\n","chain = []\n","n = 2\n","state = 0\n","m = 30\n","chain.append(state)\n","\n","for i in range(30):\n","    state = sum(np.arange(n)*np.random.multinomial(1, p[state]))\n","    chain.append(state + 1)\n","\n","print(chain)"]},{"cell_type":"code","source":["import numpy as np\n","\n","\n","# initial guess for the stationary distribution\n","stationary_dist = np.array([0.5, 0.5])\n","\n","# convergence criterion\n","epsilon = 1e-6\n","\n","# iteration to find the stationary distribution\n","while True:\n","    new_sd = np.dot(stationary_dist, p)\n","    if np.max(np.abs(new_sd - stationary_dist)) < epsilon:\n","        break\n","    stationary_dist = new_sd\n","\n","# normalize the pi vector to ensure it's a valid probability distribution\n","stationary_dist /= np.sum(stationary_dist)\n","\n","print(\"Stationary distribution:\", stationary_dist)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"owJIqSYPEBha","executionInfo":{"status":"ok","timestamp":1697553478390,"user_tz":180,"elapsed":273,"user":{"displayName":"Bernardo Ávila","userId":"17720466755867390545"}},"outputId":"cc863573-6c6e-468f-c3b0-894cae85faa3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Stationary distribution: [0.25000064 0.74999936]\n"]}]},{"cell_type":"code","source":["dict1 = {'e': 0.13, 'o': 0.091, 's': 0.086, 'a': 0.082, 't': 0.08, 'n': 0.068, 'r': 0.06, 'i': 0.056, 'l': 0.047, 'm': 0.047, 'd': 0.041, 'u': 0.025,\n","        'p': 0.02, 'q': 0.02, 'w': 0.02, 'z':0.02, 'b': 0.01, 'c': 0.01, 'f': 0.01, 'g': 0.01, 'h':0.009 , 'j':0.0088}\n","\n","import math\n","\n","# inicialize entropy as 0\n","entropy = 0\n","\n","# calculate entropy using formula\n","for event, probability in dict1.items():\n","    entropy -= probability * math.log2(probability)\n","\n","print(f\"Entropy of the distribution is: {entropy}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8KstVDLi9xfs","executionInfo":{"status":"ok","timestamp":1697552241227,"user_tz":180,"elapsed":6,"user":{"displayName":"Bernardo Ávila","userId":"17720466755867390545"}},"outputId":"0b2ecd22-2fd9-4427-a3ce-e9fd2a25786b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["A entropia da distribuição é: 3.9043873880542472\n"]}]},{"cell_type":"code","source":["import math\n","\n","# probability of the letter 'e'\n","probability_e = 0.13\n","\n","# formula to calculate the number of bits\n","bits_required = (math.ceil(math.log2(1 / probability_e)))\n","\n","print(f\"To represent 'e' optimally, you need {bits_required} bits.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VNMgaOhTA58V","executionInfo":{"status":"ok","timestamp":1697552543770,"user_tz":180,"elapsed":4,"user":{"displayName":"Bernardo Ávila","userId":"17720466755867390545"}},"outputId":"01ae45bb-df56-47e5-89e3-11f9116417f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["To represent 'e' optimally, you need 3 bits.\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","class Node:\n","    def __init__(self):\n","        self.feature_index = None\n","        self.children = {}\n","        self.class_label = None\n","\n","def entropy(labels):\n","\n","    p = labels.mean()\n","    if p == 0 or p == 1:\n","        return 0\n","    return -p * np.log2(p) - (1 - p) * np.log2(1 - p)\n","\n","def information_gain(data, labels, feature_index):\n","\n","    n = len(labels)\n","    values = data[:, feature_index]\n","    unique_values = np.unique(values)\n","    weighted_entropy = 0\n","\n","    for value in unique_values:\n","        value_indices = np.where(values == value)\n","        subset_labels = labels[value_indices]\n","        subset_entropy = entropy(subset_labels)\n","        weighted_entropy += len(value_indices[0]) / n * subset_entropy\n","\n","    return entropy(labels) - weighted_entropy\n","\n","def id3(data, labels, features):\n","\n","    if len(np.unique(labels)) == 1:\n","        leaf = Node()\n","        leaf.class_label = labels[0]\n","        return leaf\n","    if len(features) == 0:\n","        leaf = Node()\n","        leaf.class_label = np.argmax(np.bincount(labels))\n","        return leaf\n","\n","    best_feature = max(features, key=lambda feature_index: information_gain(data, labels, feature_index))\n","\n","    node = Node()\n","    node.feature_index = best_feature\n","\n","    unique_values = np.unique(data[:, best_feature])\n","    for value in unique_values:\n","        value_indices = np.where(data[:, best_feature] == value)\n","        subset_data = data[value_indices]\n","        subset_labels = labels[value_indices]\n","        subset_features = [f for f in features if f != best_feature]\n","        child = id3(subset_data, subset_labels, subset_features)\n","        node.children[value] = child\n","\n","    return node\n","\n","Dset = np.array([\n","    [0, 0, 0, 1],\n","    [1, 1, 1, 1],\n","    [0, 1, 1, 0],\n","    [1, 1, 0, 0],\n","    [1, 0, 1, 0],\n","    [0, 1, 1, 1],\n","    [0, 0, 0, 0],\n","    [1, 0, 1, 0],\n","    [1, 1, 1, 1],\n","    [1, 0, 1, 1],\n","    [1, 0, 0, 1],\n","    [0, 1, 1, 0],\n","    [1, 0, 0, 1],\n","    [0, 0, 0, 1],\n","    [0, 1, 1, 0],\n","    [1, 1, 1, 1],\n","    [0, 1, 1, 0],\n","    [0, 0, 0, 1],\n","    [1, 0, 0, 1],\n","    [1, 1, 1, 0]])\n","\n","\n","data = Dset[:, :-1]\n","labels = Dset[:, -1]\n","\n","\n","features = list(range(data.shape[1]))\n","\n","\n","tree = id3(data, labels, features)\n","\n","\n","def print_tree(node, depth=0):\n","    prefix = \"  \" * depth\n","    if node.feature_index is not None:\n","        print(prefix + f\"Feature {node.feature_index}:\")\n","        for value, child in node.children.items():\n","            print(prefix + f\"  Value {value}:\")\n","            print_tree(child, depth + 2)\n","    else:\n","        print(prefix + f\"Class Label: {node.class_label}\")\n","\n","print_tree(tree)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6nnDnPdDBCx2","executionInfo":{"status":"ok","timestamp":1697555867642,"user_tz":180,"elapsed":359,"user":{"displayName":"Bernardo Ávila","userId":"17720466755867390545"}},"outputId":"f2bec4f7-2b09-411f-cbc2-8a0b6c851022"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Feature 2:\n","  Value 0:\n","    Feature 1:\n","      Value 0:\n","        Feature 0:\n","          Value 0:\n","            Class Label: 1\n","          Value 1:\n","            Class Label: 1\n","      Value 1:\n","        Class Label: 0\n","  Value 1:\n","    Feature 0:\n","      Value 0:\n","        Feature 1:\n","          Value 1:\n","            Class Label: 0\n","      Value 1:\n","        Feature 1:\n","          Value 0:\n","            Class Label: 0\n","          Value 1:\n","            Class Label: 1\n"]}]},{"cell_type":"code","source":["\"\"\"Feature 2 is the first decision layer.\n","\n","Value 0: This means that if the value of Feature 2 is 0, you proceed to the next decision layer.\n","\n","Feature 1: It's the next decision layer.\n","\n","Value 0: If the value of Feature 1 is 0, continue in the tree.\n","\n","Feature 0: Another decision layer.\n","\n","Value 0: If the value of Feature 0 is 0, you reach a leaf of the tree.\n","\n","Class Label: 1 - This means that based on the provided features and values, the instance is classified as 1.\n","Value 1: If the value of Feature 0 is 1, you reach another leaf.\n","\n","Class Label: 1 - Again, the instance is classified as 1.\n","Value 1: If the value of Feature 1 is 1, you reach another leaf.\n","\n","Class Label: 0 - The instance is classified as 0.\n","Value 1: If the value of Feature 2 is 1, you go to the next decision layer.\n","\n","Feature 0: Another decision layer.\n","\n","Value 0: If the value of Feature 0 is 0, you go to the next layer.\n","\n","Feature 1: Another decision layer.\n","\n","Value 1: If the value of Feature 1 is 1, you reach a leaf.\n","\n","Class Label: 0 - The instance is classified as 0.\n","Value 1: If the value of Feature 0 is 1, you proceed to the next layer.\n","\n","Feature 1: Another decision layer.\n","\n","Value 0: If the value of Feature 1 is 0, you reach a leaf.\n","\n","Class Label: 0 - The instance is classified as 0.\n","Value 1: If the value of Feature 1 is 1, you reach a leaf.\n","\n","Class Label: 1 - The instance is classified as 1.\"\"\""],"metadata":{"id":"Z79LjsZBNuOF"},"execution_count":null,"outputs":[]}]}